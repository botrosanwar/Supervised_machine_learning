# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14j16PHWox8KblxMMwd4zM3F3Vf9bD2y4
"""

import pandas as pd

# Step 0: Define our data

# Step 0: Define our data
x = [50, 60, 70]  # feature: house size in m²
y = [150, 180, 200]  # target: house price in k$
m = len(x)  # number of training examples


# Step 1: Initialize parameters

w = 0.0    # slope
b = 0.0    # intercept
alpha = 0.0001    # learning rate
iterations = 17    # how many steps of gradient descent

# Step 2: Compute initial cost
def compute_cost(x, y, w, b):
    m = len(x)
    cost = 0
    for i in range(m):
        f_wb = w * x[i] + b  # hypothesis
        cost += (f_wb - y[i]) ** 2
    cost = cost / (2 * m)
    return cost

initial_cost = compute_cost(x, y, w, b)
print("Initial cost:", initial_cost)

# Step 3: Gradient descent
for iter in range(iterations):
    dw = 0
    db = 0
    for i in range(m):
        f_wb = w * x[i] + b
        error = f_wb - y[i]
        dw += error * x[i]  # partial derivative w.r.t w
        db += error  # partial derivative w.r.t b
    dw = dw / m
    db = db / m

    # Update parameters
    w = w - alpha * dw
    b = b - alpha * db

    # Compute cost to see if it's decreasing
    cost = compute_cost(x, y, w, b)
    print(f"Iteration {iter + 1}: w={w:.4f}, b={b:.4f}, cost={cost:.2f}")

# Step 4: Make prediction
x_new = 65
y_pred = w * x_new + b
print(f"Predicted price for house of size {x_new} m²: {y_pred:.2f} k$")

import matplotlib.pyplot as plt

# Scatter plot of original data
plt.scatter(x, y, color='blue', label='Data points')

# Regression line
x_line = [min(x), max(x)]
y_line = [w * xi + b for xi in x_line]
plt.plot(x_line, y_line, color='red', label='Regression line')

plt.xlabel('Size (m²)')
plt.ylabel('Price (k$)')
plt.legend()
plt.show()

